{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using BERT to quantify the predictability of writing style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer-based models of language such as BERT have been used create state-of-the-art models for a wide range of NLP tasks over the past few years. \n",
    "BERT's next-sentence prediction's capability have recently been used to <a href='https://tedunderwood.com/2020/07/05/how-predictable-is-fiction/'>assess the predictability of fiction.</a> \n",
    "This notebook attempts to use another task that BERT can be trained on, masked language modeling, to assess the predictability of style within a single sentence.\n",
    "\n",
    "In lay language, masked language modeling can be described as a fill-in-the-blanks task. A model is given a sentence, each token in the sentence is hidden and the model made to predict it using the surrounding context words. The idea is that we can use the probabilities generated by such a model to assess how predictable the style of a sentence is. For instance, in the following English language sentence:\n",
    "\n",
    "    His hair as gold as the sun , his eyes blue like the [MASK].\n",
    "\n",
    "BERT (English) can predict `sky` with a 27.1% probability. But in the this sentence:\n",
    "\n",
    "    `The [MASK] above the port was the color of television, tuned to a dead channel`\n",
    "\n",
    "the probability of `sky` falls much lower, with BERT instead giving tokens such as `screen`, `window` or `panel` the highest probabilities - since the comparison to television makes the presence of the word less predictable. In short, BERT is better at predicting boilerplate than original writing. \n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "I would like to extend this beyond the scope of a single word and onto the scale of a complete sentence, i.e. evaluating a sentence's predictability. This approach makes sense because the way BERT computes probability would reflect a couple of things typically associated with literary originality: \n",
    "- the \"preciosity\" of a word (given two synonyms, the rarer one will receive a lower probability)\n",
    "- the unexpectedness of comparison and literary or poetic language (we might say, in structuralist terms, that BERT's probabilities are computed following paradigmatic (predicting a word over others) and syntagmatic (based on its context) axes, whose order are subverted by the \"poetic function\" of language)\n",
    "\n",
    "This predictability score could then be used as a metric for literary creativity. Being able to quantify such a value would be interesting for literary history and comparative literature, for instance if we were to compare it against signs of literary recognition (literary prizes, publication in prestigious or non-prestigious publishing houses...), enabling us to evaluate how much a certain literary culture values conformity over creativity (or vice-versa) at a certain point in time.\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "The insight that a language model can be used to assert how \"common\" the style of sentence is not entirely new. The scoring of sentences by language models, known as <a href='https://en.wikipedia.org/wiki/Perplexity#:~:text=of%20size%20N).-,Perplexity%20per%20word,over%20entire%20sentences%20or%20texts.'>perplexity</a> has been used in tasks such as automatic translation to rate which of the outputs of a model might be the most well-formed sentence in a particular target language. The main differences with our case are that:\n",
    "1. Traditional language models are sequential, working from left to right, (they don't use the whole sentence as context to predict a single word).\n",
    "2. Working with literary texts, we can assume that the sentences we will feed into the model will be generally gramatically correct (or intentionally incorrect). This allows us to be more selective in the categories of word we want to evaluate, skipping pronouns or particles (*still requires further investigation*).\n",
    "\n",
    "Regarding point 1, BERT gives us an advantage over sequential language models. Because it is bi-directional, it allows us to consider the context on both sides of a word, which is closer to how a human reader would assert the unexpectedness of a single word within a sentence. One <a href=' https://arxiv.org/pdf/1906.00363.pdf'>paper</a> averaged the probabilities of the tokens in a sentence ($\\prod_{i=1}^{n}p(w_{i}|w_{1},...,w_{i-1},w_{i+1},...,w_{n}))^{-1/n} $) to predict whether a sentence is non-sensical or not - similar to how the perplexity score is used by sequential language models.\n",
    "\n",
    "Point 2 is tied to language specific issues, adressed below.\n",
    "\n",
    "### Language specifics\n",
    "\n",
    "Working with Korean and with literary texts, the above formula seems to present some limitations. For instance, Korean can mark the object of a verb with a specific particle (를/을). Predicting this particle being present between a noun and a verb is not hard (tokenizers such as BERT's separate it from the noun to which it would be attached). Therefore the token would be assigned a high probability. However, case particles can and are often omitted depending on context and individual preferences. Including it in the scoring of a sentence might therefore introduce bias, ranking writers who use it extensively as less creative than writers who use it more sparingly. On the other hand, as noted in Point 2 above, we are not interested in evaluating the grammatical correctness of a sentence, and therefore including case particles bring little additional information to our metric. The same is true of punctuation, pronouns, prepositions... We therefore opt to restrict the model to predicting masked nouns, adjectives and verbs (all tokens are still nonetheless used as context).\n",
    "\n",
    "### Technical specifics\n",
    "\n",
    "This approach requires us to be able to control the tokenization process because we want to be able to select the words which we will mask for prediction. Because most implementations of BERT uses a type of tokenizer that works splitting more complex words into smaller words to retain a small vocabulary size. This choice of tokenizing method is a powerful way to deal with out-of-vocabulary words (they will be split into smaller, in-vocabulary pieces). \n",
    "\n",
    "To address this issue, I've pre-tokenized the training data used during fine-tuning. I then train a new tokenizer with a large dictionary size and use its vocabulary to update the tokenizer's vocabulary of the base BERT model used for fine-tuning. (see <a href='https://github.com/digitalprk/sih_notebooks/blob/master/run_language_modeling.py'>here</a>). (Note that this extra step would not be needed if we did not want to exclude certain grammatical categories: we could simply use the mean of the probabilities of the differents parts of a word that was split as the probability of that word).\n",
    "\n",
    "The base model used was <a href='https://github.com/SKTBrain/KoBERT'>KoBERT</a>, a BERT model trained by the SK Telecom team on South Korean language data. The model was fine-tuned on a small (1.6Gb) corpus of North Korean language data comprising novels, literary journals, newspapers, non-fiction books and the complete works of Kim Il-Sung and Kim Jong-Il.\n",
    "\n",
    "### Data\n",
    "\n",
    "10000 Sentences were extracted from four types of sources:\n",
    "1. The Korean Central News Agency (the North Korean state's press agency)\n",
    "2. Novels by prestigious writers (recognized for their literary excellence with a state sanctioned distinction)\n",
    "3. Novels by \"regular\" writers\n",
    "4. Canonical novels (fictional accounts of the lives of Kim Il-Sung and Kim Jong-Il held to be of the highest literary quality). \n",
    "5. Collections of poetry\n",
    "\n",
    "None of the novels or press releases used were present in the corpus used to fine-tune the model. However, the corpus did contain similar content (literary sources and press releases for different years). All content used came from the years 1967 - 2018.\n",
    "\n",
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x27133b2ad48>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "df.boxplot(figsize = (15, 10), showfliers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Canonical Novels.txt</th>\n",
       "      <th>Central News Agency.txt</th>\n",
       "      <th>Poetry.txt</th>\n",
       "      <th>Prestigious Novels.txt</th>\n",
       "      <th>Regular Novels.txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000251</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>3.717125e-04</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.000246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>7.810524e-04</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.000247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.595703e-07</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>9.288890e-05</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>1.920330e-04</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>3.979100e-04</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.000288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.008501</td>\n",
       "      <td>0.002298</td>\n",
       "      <td>3.953910e-02</td>\n",
       "      <td>0.007767</td>\n",
       "      <td>0.004886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Canonical Novels.txt  Central News Agency.txt    Poetry.txt  \\\n",
       "count          10000.000000             10000.000000  1.000000e+04   \n",
       "mean               0.000251                 0.000243  3.717125e-04   \n",
       "std                0.000270                 0.000141  7.810524e-04   \n",
       "min                0.000000                 0.000000  4.595703e-07   \n",
       "25%                0.000120                 0.000149  9.288890e-05   \n",
       "50%                0.000187                 0.000214  1.920330e-04   \n",
       "75%                0.000297                 0.000301  3.979100e-04   \n",
       "max                0.008501                 0.002298  3.953910e-02   \n",
       "\n",
       "       Prestigious Novels.txt  Regular Novels.txt  \n",
       "count            10000.000000        10000.000000  \n",
       "mean                 0.000257            0.000246  \n",
       "std                  0.000307            0.000247  \n",
       "min                  0.000004            0.000003  \n",
       "25%                  0.000116            0.000115  \n",
       "50%                  0.000184            0.000183  \n",
       "75%                  0.000299            0.000288  \n",
       "max                  0.007767            0.004886  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Canonical Novels.txt : Central News Agency.txt\n",
      "Ttest_indResult(statistic=2.552955486164272, pvalue=0.010688673312532326)\n",
      "Canonical Novels.txt : Poetry.txt\n",
      "Ttest_indResult(statistic=-14.648423341306692, pvalue=2.4547739726797334e-48)\n",
      "Canonical Novels.txt : Prestigious Novels.txt\n",
      "Ttest_indResult(statistic=-1.4728912652748583, pvalue=0.14079609596087897)\n",
      "Canonical Novels.txt : Regular Novels.txt\n",
      "Ttest_indResult(statistic=1.3942278524406801, pvalue=0.16326429911179666)\n",
      "Central News Agency.txt : Poetry.txt\n",
      "Ttest_indResult(statistic=-16.231165951078893, pvalue=7.223306925742566e-59)\n",
      "Central News Agency.txt : Prestigious Novels.txt\n",
      "Ttest_indResult(statistic=-4.08177938362255, pvalue=4.486578683061665e-05)\n",
      "Central News Agency.txt : Regular Novels.txt\n",
      "Ttest_indResult(statistic=-0.9394757646506924, pvalue=0.34749787648814956)\n",
      "Poetry.txt : Prestigious Novels.txt\n",
      "Ttest_indResult(statistic=13.705254034128503, pvalue=1.4707000490328944e-42)\n",
      "Poetry.txt : Regular Novels.txt\n",
      "Ttest_indResult(statistic=15.39951471105084, pvalue=3.3320854522790646e-53)\n",
      "Prestigious Novels.txt : Regular Novels.txt\n",
      "Ttest_indResult(statistic=2.821911884969821, pvalue=0.004778536989939926)\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "from itertools import combinations\n",
    "for a, b in list(combinations(df.columns, 2)):\n",
    "    print(f'{a} : {b}')\n",
    "    print(stats.ttest_ind(df[a],df[b]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments\n",
    "\n",
    "- The method seems to be at least working for discriminating between discursive genres\n",
    "- Poetry might be expected to be the genre with the most creative writing, however the higher predictability of contemporary North Korean poetry is not really surprising for anyone unfortunate enough to be familiar with it.\n",
    "- The method shows little significant difference between subgroups of fiction writing. This may be because there's none and all rely, on average, on the same amount of boilerplate. Comparisons between individual writers might be more meaningful. Other possibilities: issues with the fine-tuned model, wrong assumption that the method can be used indiscriminately on any sentence of a text (need to filter at least dialogue, or select for metaphoric sentences with metaphor detection, wrong assumption that the method actually works as intended...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0922 20:18:56.668476 39944 file_utils.py:39] PyTorch version 1.6.0 available.\n",
      "I0922 20:18:58.622256 39944 file_utils.py:55] TensorFlow version 2.2.0 available.\n",
      "I0922 20:18:59.258558 39944 configuration_utils.py:262] loading configuration file ./jobert\\config.json\n",
      "I0922 20:18:59.259525 39944 configuration_utils.py:300] Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 20839\n",
      "}\n",
      "\n",
      "I0922 20:18:59.260535 39944 tokenization_utils_base.py:1167] Model name './jobert' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, TurkuNLP/bert-base-finnish-cased-v1, TurkuNLP/bert-base-finnish-uncased-v1, wietsedv/bert-base-dutch-cased). Assuming './jobert' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "I0922 20:18:59.261519 39944 tokenization_utils_base.py:1197] Didn't find file ./jobert\\added_tokens.json. We won't load it.\n",
      "I0922 20:18:59.262517 39944 tokenization_utils_base.py:1197] Didn't find file ./jobert\\tokenizer.json. We won't load it.\n",
      "I0922 20:18:59.264512 39944 tokenization_utils_base.py:1252] loading file ./jobert\\vocab.txt\n",
      "I0922 20:18:59.265509 39944 tokenization_utils_base.py:1252] loading file None\n",
      "I0922 20:18:59.266536 39944 tokenization_utils_base.py:1252] loading file ./jobert\\special_tokens_map.json\n",
      "I0922 20:18:59.267507 39944 tokenization_utils_base.py:1252] loading file ./jobert\\tokenizer_config.json\n",
      "I0922 20:18:59.268530 39944 tokenization_utils_base.py:1252] loading file None\n",
      "C:\\WPy64-3740\\python-3.7.4.amd64\\lib\\site-packages\\transformers\\modeling_auto.py:798: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  FutureWarning,\n",
      "I0922 20:18:59.286481 39944 configuration_utils.py:262] loading configuration file ./jobert\\config.json\n",
      "I0922 20:18:59.287451 39944 configuration_utils.py:300] Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 20839\n",
      "}\n",
      "\n",
      "I0922 20:18:59.288448 39944 modeling_utils.py:665] loading weights file ./jobert\\pytorch_model.bin\n",
      "I0922 20:19:01.379858 39944 modeling_utils.py:765] All model checkpoint weights were used when initializing BertForMaskedLM.\n",
      "\n",
      "I0922 20:19:01.380856 39944 modeling_utils.py:774] All the weights of BertForMaskedLM were initialized from the model checkpoint at ./jobert.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use BertForMaskedLM for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
    "import torch\n",
    "import logging\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "logging.getLogger(\"transformers.tokenization_utils\").setLevel(logging.ERROR)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./jobert\")\n",
    "model = AutoModelWithLMHead.from_pretrained(\"./jobert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Komoran\n",
    "komoran = Komoran()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_word_proba(sequence, word):\n",
    "    global model, tokenizer\n",
    "    input_ids = tokenizer.encode(sequence, return_tensors=\"pt\")\n",
    "    mask_token_index = torch.where(input_ids == tokenizer.mask_token_id)[1]\n",
    "    token_logits = model(input_ids)[0]\n",
    "    mask_token_logits = token_logits[0, mask_token_index, :]\n",
    "    mask_token_logits = torch.softmax(mask_token_logits, dim=1)\n",
    "    sought_after_token = word\n",
    "    sought_after_token_id = tokenizer.encode(sought_after_token, add_special_tokens=False, add_prefix_space=True)[0]\n",
    "    token_score = mask_token_logits[:, sought_after_token_id]\n",
    "    return token_score.detach().numpy()[0]\n",
    "\n",
    "def compute_word_by_word_proba(sequence):\n",
    "    global tokenizer\n",
    "    global komoran\n",
    "    pos_filter = ['VV', 'VA', 'NNG', 'NNP', 'MAG', 'NA', 'SN', 'NR', 'XR'] # we only want to predict verbs, nouns and adjectives\n",
    "    word_dict = {}\n",
    "    tokenized_sequence = komoran.pos(sequence)\n",
    "    sequence = ' '.join([token for token, pos in tokenized_sequence])\n",
    "    for token, pos in tokenized_sequence:\n",
    "        #print(token, pos)\n",
    "        if pos in pos_filter:\n",
    "            masked_sequence = sequence.replace(token, tokenizer.mask_token)\n",
    "            word_dict[token] = compute_word_proba(masked_sequence, token)\n",
    "    return word_dict\n",
    "\n",
    "def geometric_mean(series):\n",
    "    return np.array(series, dtype=np.float64).prod()**(1.0/len(series))\n",
    "\n",
    "def compute_sentence_score(sentence):\n",
    "    return geometric_mean(list(compute_word_by_word_proba(sentence).values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Canonical Novels.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [1:34:02<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Central News Agency.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [3:43:23<00:00,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poetry.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [19:56<00:00,  8.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prestigious Novels.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████████▍                                                                                                                                                          | 516/10000 [04:06<1:54:47,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: ≪그가 무엇 때문에 여기에 왔지?\n",
      "float division by zero\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [1:23:32<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regular Novels.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [1:18:22<00:00,  2.80it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "sample_data_path = './samples'\n",
    "sample_files = [file for file in os.listdir(sample_data_path) if not file.endswith('-tokenized.txt')]\n",
    "final_results = {}\n",
    "for file in sample_files:\n",
    "    with open(os.path.join(sample_data_path, file), 'r', encoding='utf8') as fp:\n",
    "        sentences = fp.read().splitlines()\n",
    "    scores = []\n",
    "    print(file)\n",
    "    for i, sentence in enumerate(tqdm(sentences)):\n",
    "        try:\n",
    "            score = compute_sentence_score(sentence.replace('\\xa0 ', ''))\n",
    "            scores.append(score)\n",
    "        except Exception as e:\n",
    "            scores.append(np.mean(scores))\n",
    "            print(\"Error:\", sentence)\n",
    "            print(e)\n",
    "            pass\n",
    "    \n",
    "    final_results[file] = scores\n",
    "    \n",
    "#with open('/project/RDS-FASS-NKBert-RW/samples/final_scores.pkl', 'wb') as fp:\n",
    "#    pickle.dump(final_results, fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Canonical Novels.txt</th>\n",
       "      <th>Central News Agency.txt</th>\n",
       "      <th>Poetry.txt</th>\n",
       "      <th>Prestigious Novels.txt</th>\n",
       "      <th>Regular Novels.txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000369</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>0.001218</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>0.000109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.000079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>0.000136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.000151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.000127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.000887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.000354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.000514</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Canonical Novels.txt  Central News Agency.txt  Poetry.txt  \\\n",
       "0                 0.000140                 0.000181    0.000047   \n",
       "1                 0.000369                 0.000135    0.000053   \n",
       "2                 0.000126                 0.000354    0.001218   \n",
       "3                 0.000076                 0.000345    0.000088   \n",
       "4                 0.000206                 0.000132    0.000467   \n",
       "...                    ...                      ...         ...   \n",
       "9995              0.000259                 0.000228    0.000096   \n",
       "9996              0.000187                 0.000189    0.000297   \n",
       "9997              0.000136                 0.000141    0.000169   \n",
       "9998              0.000147                 0.000330    0.000036   \n",
       "9999              0.000514                 0.000191    0.000066   \n",
       "\n",
       "      Prestigious Novels.txt  Regular Novels.txt  \n",
       "0                   0.000030            0.000079  \n",
       "1                   0.000111            0.000200  \n",
       "2                   0.000450            0.000109  \n",
       "3                   0.000226            0.000079  \n",
       "4                   0.000308            0.000136  \n",
       "...                      ...                 ...  \n",
       "9995                0.000259            0.000151  \n",
       "9996                0.000161            0.000127  \n",
       "9997                0.000115            0.000887  \n",
       "9998                0.000213            0.000354  \n",
       "9999                0.000066            0.000236  \n",
       "\n",
       "[10000 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(final_results)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x27132e8ce08>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "df.boxplot(figsize = (20, 10), showfliers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Canonical Novels.txt</th>\n",
       "      <th>Central News Agency.txt</th>\n",
       "      <th>Poetry.txt</th>\n",
       "      <th>Prestigious Novels.txt</th>\n",
       "      <th>Regular Novels.txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000251</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>3.717125e-04</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.000246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>7.810524e-04</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.000247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.595703e-07</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>9.288890e-05</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>1.920330e-04</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>3.979100e-04</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.000288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.008501</td>\n",
       "      <td>0.002298</td>\n",
       "      <td>3.953910e-02</td>\n",
       "      <td>0.007767</td>\n",
       "      <td>0.004886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Canonical Novels.txt  Central News Agency.txt    Poetry.txt  \\\n",
       "count          10000.000000             10000.000000  1.000000e+04   \n",
       "mean               0.000251                 0.000243  3.717125e-04   \n",
       "std                0.000270                 0.000141  7.810524e-04   \n",
       "min                0.000000                 0.000000  4.595703e-07   \n",
       "25%                0.000120                 0.000149  9.288890e-05   \n",
       "50%                0.000187                 0.000214  1.920330e-04   \n",
       "75%                0.000297                 0.000301  3.979100e-04   \n",
       "max                0.008501                 0.002298  3.953910e-02   \n",
       "\n",
       "       Prestigious Novels.txt  Regular Novels.txt  \n",
       "count            10000.000000        10000.000000  \n",
       "mean                 0.000257            0.000246  \n",
       "std                  0.000307            0.000247  \n",
       "min                  0.000004            0.000003  \n",
       "25%                  0.000116            0.000115  \n",
       "50%                  0.000184            0.000183  \n",
       "75%                  0.000299            0.000288  \n",
       "max                  0.007767            0.004886  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Canonical Novels.txt : Central News Agency.txt\n",
      "Ttest_indResult(statistic=2.552955486164272, pvalue=0.010688673312532326)\n",
      "Canonical Novels.txt : Poetry.txt\n",
      "Ttest_indResult(statistic=-14.648423341306692, pvalue=2.4547739726797334e-48)\n",
      "Canonical Novels.txt : Prestigious Novels.txt\n",
      "Ttest_indResult(statistic=-1.4728912652748583, pvalue=0.14079609596087897)\n",
      "Canonical Novels.txt : Regular Novels.txt\n",
      "Ttest_indResult(statistic=1.3942278524406801, pvalue=0.16326429911179666)\n",
      "Central News Agency.txt : Poetry.txt\n",
      "Ttest_indResult(statistic=-16.231165951078893, pvalue=7.223306925742566e-59)\n",
      "Central News Agency.txt : Prestigious Novels.txt\n",
      "Ttest_indResult(statistic=-4.08177938362255, pvalue=4.486578683061665e-05)\n",
      "Central News Agency.txt : Regular Novels.txt\n",
      "Ttest_indResult(statistic=-0.9394757646506924, pvalue=0.34749787648814956)\n",
      "Poetry.txt : Prestigious Novels.txt\n",
      "Ttest_indResult(statistic=13.705254034128503, pvalue=1.4707000490328944e-42)\n",
      "Poetry.txt : Regular Novels.txt\n",
      "Ttest_indResult(statistic=15.39951471105084, pvalue=3.3320854522790646e-53)\n",
      "Prestigious Novels.txt : Regular Novels.txt\n",
      "Ttest_indResult(statistic=2.821911884969821, pvalue=0.004778536989939926)\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "from itertools import combinations\n",
    "for a, b in list(combinations(df.columns, 2)):\n",
    "    print(f'{a} : {b}')\n",
    "    print(stats.ttest_ind(df[a],df[b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-1.6062157018139056, pvalue=0.10825810476960021)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "stats.ttest_ind(df['novels.txt'], df['novels-415.txt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "poem = ['예순여해!', \n",
    "'세월은 많이 흘렀어도', \n",
    "'지나간 추억의 이야기 아니여라', \n",
    "'오늘도 우리앞에', \n",
    "'통일로 펼쳐지는 이야기', \n",
    "'해방후', \n",
    "'38°선이 처음 그어질 땐 북녘땅', \n",
    "'전쟁이 끝난 다음엔 남녘땅', \n",
    "'강원도 고성군 화진포에 깃든', \n",
    "'못 잊을 8월이야기', \n",
    "'절세의 위인들 사랑 뜨거운', \n",
    "'여름이야기여', \n",
    "'해방!', \n",
    "'해방은 되였어도', \n",
    "'그 기쁨 다 모르고 사는 고장', \n",
    "'산넘어 38°선이 보이는', \n",
    "'초도리 화진포', \n",
    "'해종일 물밑을 뒤져도', \n",
    "'모래밭에 널린 조가비처럼', \n",
    "'아직도 가난이 널린 마을', \n",
    "'이따금 쿵쿵 포소리 울려와', \n",
    "'사람들 불안을 안고사는 화진포', \n",
    "'그래도 경치는 수려했다', \n",
    "'은빛모래밭에 진분홍색 해당화', \n",
    "'남색의 파도우에 거부기모양의 섬', \n",
    "'섬우엔 병풍처럼 펼쳐진 푸른 솔숲', \n",
    "'그 솔숲에서 봄이면 날려오는', \n",
    "'노란 솔꽃가루 물결에 실리고', \n",
    "'여름내내 해당화 진한 향기', \n",
    "'바람타고 감도는 포구여서', \n",
    "'그 이름도 화진포', \n",
    "'그날이였다', \n",
    "'해방전 가진자들의 흥타령 울리던', \n",
    "'해변가 신작로따라', \n",
    "'차창에 석양빛 싣고', \n",
    "'달려오는 승용차 한대', \n",
    "'해넘이경치 보러오는걸가', \n",
    "'해당화 꽃구경 오는걸가', \n",
    "'하늘가엔 노을도 곱게 피는데', \n",
    "'어인 일인가', \n",
    "'기울어진 울바자 힘겹게 서있는', \n",
    "'마을어구에서 문득 멈춰서는 승용차', \n",
    "'슬픔을 먹고자란 생명인가', \n",
    "'시들은 유채꽃처럼', \n",
    "'얼굴이 노랗게 뜬 어린 소녀', \n",
    "'바다쪽에 눈길을 얹고', \n",
    "'마을길에 서있었다', \n",
    "'가난이 숨길수 없이 내비친듯', \n",
    "'다섯발가락이 다 나온', \n",
    "'터진 고무신을 신고 서있는 소녀', \n",
    "'그 모습에 눈길을 떼지 못하시며', \n",
    "'차에서 내리신 현숙한 녀사분과 자제분', \n",
    "'불쌍한 아이들을 두고서는', \n",
    "'눈물도 많으신분', \n",
    "'38°선 가까이서 그 모습을 보니', \n",
    "'가슴에 소금이 뿌려진듯', \n",
    "'더 아파 못 견디시는', \n",
    "'아, 그분은', \n",
    "'항일의 녀장군 김정숙어머님', \n",
    "'－몇살이예요?', \n",
    "'－여섯살!', \n",
    "'－왜 여기 서있나요?', \n",
    "'－아빠가 보고싶어서…', \n",
    "'－아빠는 어디 가셨게?', \n",
    "'－고기잡이 나갔다가', \n",
    "'  38°선이 막혀 못 온대요', \n",
    "'  돌아오면 꽃신을 꼭 사주겠다고 했는데…', \n",
    "'꿰진 신발과 해진 옷을 걸치고', \n",
    "'분렬조국의 기슭에 나와선', \n",
    "'어린 소녀', \n",
    "'품에 꼭 껴안으신 어머님', \n",
    "'어머님 눈빛은', \n",
    "'저도몰래 젖어드셨다', \n",
    "'어릴적 부암동 하촌마을에서', \n",
    "'피덩이 어린 조카를 안고', \n",
    "'오빠를 기다리던 그날이 생각나', \n",
    "'그날의 자신의 모습', \n",
    "'여기서 다시 보는것만 같아', \n",
    "'진정 그랬다', \n",
    "'일제놈들때문에 당한', \n",
    "'그 생리별의 아픔', \n",
    "'해가고 달가도 가실길 없는데', \n",
    "'미국놈들때문에 또다시', \n",
    "'이런 비극 당해야 한단 말인가', \n",
    "'어머님은 비분을 누르시며', \n",
    "'조용히 말씀하신다', \n",
    "'－얘야 우리 경치좋은 이곳에', \n",
    "'  이제 학교랑 유희장이랑 짓자꾸나', \n",
    "'  그때면', \n",
    "'  새 옷도 새 신발도 다 거저주려 한다', \n",
    "'  헤여진 아버지도 만나구 … 좋지?', \n",
    "'순간,', \n",
    "'머리를 번쩍 든 소녀', \n",
    "'나서 처음 해빛을 마주한듯', \n",
    "'눈빛을 반짝이며 우러렀다', \n",
    "'다정하신 그분을', \n",
    "'가슴속에 무지개가 떴다', \n",
    "'그 고운 칠색에 고운 꿈을 실을제', \n",
    "'새 신을 안고 달려오신 자제분', \n",
    "'그분은 빨찌산의 아들 김정일장군님', \n",
    "'처녀애의 터진 고무신을 벗기고', \n",
    "'새 신발을 신겨주시였다', \n",
    "'－어서 신어라 이건 내 신발인데', \n",
    "'  네 발에 꼭 맞을거야', \n",
    "'  그리고 아빠때문에', \n",
    "'  너무 마음쓰지 말어', \n",
    "'  38°선 철조망을 걷어주시려', \n",
    "'  아버지 김일성장군님께서', \n",
    "'  우리 어머님과 함께 화진포에 오셨어', \n",
    "'화진포에 가면 신으라고', \n",
    "'수령님 사주신 신발', \n",
    "'어머님께서 신끈도 곱게 매여주시여', \n",
    "'아직 한번도 신지 않고', \n",
    "'아끼고아끼시던 새 구두', \n",
    "'아끼지 않고 주시였다', \n",
    "'겨레를 위해 늘 마음쓰시는', \n",
    "'수령님과 어머님사랑', \n",
    "'자신의 마음에 가득 담으시여', \n",
    "'아빠찾는 소녀의 가슴에', \n",
    "'기쁨으로 가득 안겨주시였다', \n",
    "'순간 솟구치는', \n",
    "'감사의 인사말 올리는것인가', \n",
    "'가랑가랑 눈굽에 구슬을 달고', \n",
    "'여섯살 어린 소녀', \n",
    "'아뢰인 다만 한마디', \n",
    "'오빠!－', \n",
    "'그렇다 그분이 누구신지', \n",
    "'소녀는 아직 알수 없었어도', \n",
    "'어린 가슴속에', \n",
    "'그분은 벌써 친오빠', \n",
    "'기쁨으로 우러른', \n",
    "'행복의 세상이시였다', \n",
    "'소녀는 달려간다', \n",
    "'새 신을 안고', \n",
    "'춤을 추듯 백사장으로', \n",
    "'아빠!－ 소리쳐 부르며', \n",
    "'그 소리', \n",
    "'바다가 멀리멀리 메아리치는데', \n",
    "'소녀가 찾는 아빠', \n",
    "'어디에 있는가', \n",
    "'어머님은 오래도록', \n",
    "'자리를 뜨지 못하신다', \n",
    "'산에서 얼고 굶으며', \n",
    "'피흘려 찾은 조국이건만', \n",
    "'마주하신것은', \n",
    "'갈라진 민족의 비극', \n",
    "'분렬의 아픈 상처', \n",
    "'산에서 10여성상 쌓이신 피로', \n",
    "'예와서 푸시면 얼마나 좋으랴', \n",
    "'해방된 조국의 명소에 오셨어도', \n",
    "'아름다운 경치 비켜서시여', \n",
    "'갈라진 겨레의 불행 안으시고', \n",
    "'자리를 뜨지 못하시나니', \n",
    "'오, 물어보자', \n",
    "'삼천리조국이여 화진포여', \n",
    "'너는 어머님께 아픔만 드리자고', \n",
    "'어제는 일제의 칼에 맞아 피흘리고', \n",
    "'오늘은 허리잘려 신음하느냐', \n",
    "'이렇게 오시였다 어머님은', \n",
    "'38°선이 보이는 분렬의 현장으로', \n",
    "'이 땅의 울분을 안으시고', \n",
    "'민족의 통한을 안으시고', \n",
    "'해방소원 안으셨던 가슴에', \n",
    "'통일소원 또다시 무겁게 안으시고', \n",
    "'차는 달린다 어둠을 뚫고', \n",
    "'아빠찾는 소녀의 모습', \n",
    "'갈라진 겨레의 아픔', \n",
    "'크나큰 위업속에 싣고', \n",
    "'오, 그날부터 화진포에', \n",
    "'어머님 휴식의 밤은 없었다', \n",
    "'2', \n",
    "'날이 밝았다', \n",
    "'아빠가 돌아오면 보여주리', \n",
    "'새 신발 가슴에 안고', \n",
    "'이른 새벽부터', \n",
    "'바다가 모래불에 나와 선', \n",
    "'어린 소녀', \n",
    "'철썩 처절썩－', \n",
    "'몇백 몇천번이나 파도는', \n",
    "'기슭에 달려와 안겨도', \n",
    "'오늘도 안 오시는 아빠', \n",
    "'언제면 오실가', \n",
    "'저녁노을 등에 지고', \n",
    "'맥없이 집에 들어서는데', \n",
    "'그만 눈이 휘둥그래졌다', \n",
    "'엄마와 함께 부엌에서', \n",
    "'터진 부뚜막 손질하시는분', \n",
    "'그분이 어제저녁 마을길에서 만난', \n",
    "'그 고마우신 어머님이시였으니', \n",
    "'소녀의 얼굴엔 웃음꽃이 활짝 폈다', \n",
    "'세상에서 제일 좋은 큰어머님', \n",
    "'엄마와 함께 계시기에', \n",
    "'기쁨속에 새겨들었다', \n",
    "'큰어머님 엄마와 나누시는 말씀', \n",
    "'－세대주가 돌아와서', \n",
    "'  부뚜막수리를 하겠다고 했는데…', \n",
    "'  녀사님께 페를 끼쳐 정말 미안해요', \n",
    "'－괜찮아요 이제 세대주가 돌아오면', \n",
    "'  기다린 정 만난정 다 합쳐', \n",
    "'  밥을 맛있게 지어 대접하자요!', \n",
    "'친혈육인듯', \n",
    "'다정한 언니 동생인듯', \n",
    "'웃으며 허물없이 이야기를 나눌 때', \n",
    "'어린 소녀 어느새 달려와 안겼다', \n",
    "'－엄마 내가 어제 말하던', \n",
    "'  그 큰어머님이야', \n",
    "'－해선아! 나도 그렇게 생각했다', \n",
    "'모를수 없었다', \n",
    "'그분이 아니시면', \n",
    "'누가 화진포에', \n",
    "'이렇듯 큰 사랑 안고오시랴', \n",
    "'김정숙어머님! 그 이름은', \n",
    "'나라를 찾아주신', \n",
    "'김일성장군님 태양존함과 더불어', \n",
    "'삼천리에 빛나는 해발!', \n",
    "'아이들 손잡고 로인들 앞세우고', \n",
    "'동리사람들이 모여왔다', \n",
    "'친정집어머님을 모신듯', \n",
    "'사람들 빙－ 둘러앉은 해선이네 집', \n",
    "'새 삶의 기쁨을 터치는', \n",
    "'글방인가 노래방인가 웃음방인가', \n",
    "'함께 오신 자제분 또박또박 써주신', \n",
    "'《삼천리 우리 나라》 글읽는 소리', \n",
    "'어머님 배워주신', \n",
    "'《김일성장군의 노래》 부르는 소리', \n",
    "'수령님 모신 통일조국에서 행복하게 살', \n",
    "'그날을 그려보는 웃음소리', \n",
    "'아, 분렬의 종처인양 옹기종기', \n",
    "'설음이 돋아있는 동네', \n",
    "'집집마다 가슴마다 기쁨을 채워주는', \n",
    "'백두에서 떠나온 사랑의 큰 세계여', \n",
    "'그 품에 안겨', \n",
    "'사랑이 무엇인지 하나씩 깨달아가는', \n",
    "'화진포사람들의', \n",
    "'글소리 노래소리 웃음소리여', \n",
    "'밤이 깊었다', \n",
    "'따로 마련한 숙소', \n",
    "'마다하시는 어머님께', \n",
    "'한 녀인이 말씀올린다', \n",
    "'－녀사님, 그럼 이 모기장만이라도…', \n",
    "'풀엉킨 산기슭의 작은 집', \n",
    "'여름밤 모기장이야 어이 마다하시랴', \n",
    "'하지만 어머님', \n",
    "'누에실로 엮은 수수한 모기장앞에', \n",
    "'생각깊이 이으시는 말씀', \n",
    "'－해선이 아버지랑 함께 간 사람들이', \n",
    "'  지금 혈육들 생각하며', \n",
    "'  밤거리를 헤매는지 어떻게 알겠어요', \n",
    "'  그런데 제가 어떻게 호강스럽게', \n",
    "'  비단모기장을 치고 눕겠어요?!', \n",
    "'이 무슨 말씀이신가', \n",
    "'산에서 눈깔고 가랑잎덮고 쉬시며', \n",
    "'겪으신 고생 얼마이신데', \n",
    "'그러면 우린 어떻게 하느냐며', \n",
    "'해선이 어머닌 울어버린다', \n",
    "'－해선이 어머니, 이러지 마세요', \n",
    "'  나에겐 모포 한장이면 돼요', \n",
    "'  지금 수령님께서는 조국의 통일을 위해', \n",
    "'  화진포사람들의 생활을 위해', \n",
    "'  이 밤도 지새고계셔요', \n",
    "'  조국이 통일되는 그날까지', \n",
    "'  나는 백두산에서 몸에 밴', \n",
    "'  유격대생활습성을 바꿀것 같지 못해요', \n",
    "'－녀사님!', \n",
    "'－김정숙어머님!', \n",
    "'아, 이 밤을 울었다', \n",
    "'숲속의 이름 모를 풀잎마저', \n",
    "'맑은 이슬 소리내여 떨구며', \n",
    "'못 이룬 통일앞에 서신 어머님껜', \n",
    "'수수한 견사모기장마저', \n",
    "'그리도 사치한것이란 말인가', \n",
    "'정녕', \n",
    "'이밤엔 어유등도', \n",
    "'안타까움에 타고탔다', \n",
    "'누구나 누리는 그 작은 권리', \n",
    "'어머님은 향유하시면 안되신단 말인가', \n",
    "'어느덧 밤은 깊어', \n",
    "'외로운 포구에 정적도 깊어', \n",
    "'화진포사람들 깊은 잠 들었건만', \n",
    "'마당가에 나오신', \n",
    "'김정숙어머님', \n",
    "'마음을 진정하지 못하신다', \n",
    "'만주벌 눈바람속에서', \n",
    "'풍찬로숙하며', \n",
    "'탄알이 비발치는 전장을', \n",
    "'총들고 달리시며', \n",
    "'시련을 넘어 죽음을 넘어', \n",
    "'기어이 찾은 조국이건만', \n",
    "'그 조국의 허리에', \n",
    "'가시철조망이 칭칭 감기고', \n",
    "'해방만세의 감격 터져올랐던', \n",
    "'이 8월의 여름하늘아래서', \n",
    "'얼어드는 가슴안고 사람들 살고있으니', \n",
    "'견딜수 없으시였다', \n",
    "'용납할수 없으시였다', \n",
    "'한몸을 깡그리 불태워서라도', \n",
    "'원한의 그 찬덩어리 모두 녹이리라', \n",
    "'어머님 가슴속에선 선언이 울리셨다', \n",
    "'오, 진정', \n",
    "'이 땅의 한사람한사람이', \n",
    "'자신의 체온다해 품어주시는', \n",
    "'친혈육 친자식이여서', \n",
    "'이 땅의 한치한치가', \n",
    "'자신의 몸 한부분 같으시여', \n",
    "'조국앞에 서신 어머님은 그대로', \n",
    "'금강석도 녹여버릴', \n",
    "'불덩이 지니신 사랑의 화신이시였다', \n",
    "'삼천리를 품으신 하늘이시였다', \n",
    "'진정 억만금이 있다 해도', \n",
    "'그를 위해 모두 바치셨을', \n",
    "'통일, 통일은 어머님의', \n",
    "'최고의 기쁨', \n",
    "'최상의 재부', \n",
    "'최대의 소원', \n",
    "'사모님이라 부르는것조차', \n",
    "'한번 허락지 않으시고', \n",
    "'김일성장군님 통일전사로', \n",
    "'낮과 밤을 이으시는 어머님이시여', \n",
    "'한몸을 깡그리 불태우시는 녀장군이시여']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예순여해!\n",
      "세월은 많이 흘렀어도\n",
      "지나간 추억의 이야기 아니여라\n",
      "오늘도 우리앞에\n",
      "통일로 펼쳐지는 이야기\n",
      "38°선이 처음 그어질 땐 북녘땅\n",
      "전쟁이 끝난 다음엔 남녘땅\n",
      "강원도 고성군 화진포에 깃든\n",
      "못 잊을 8월이야기\n",
      "절세의 위인들 사랑 뜨거운\n",
      "여름이야기여\n",
      "해방은 되였어도\n",
      "그 기쁨 다 모르고 사는 고장\n",
      "산넘어 38°선이 보이는\n",
      "초도리 화진포\n",
      "해종일 물밑을 뒤져도\n",
      "모래밭에 널린 조가비처럼\n",
      "아직도 가난이 널린 마을\n",
      "이따금 쿵쿵 포소리 울려와\n",
      "사람들 불안을 안고사는 화진포\n",
      "그래도 경치는 수려했다\n",
      "은빛모래밭에 진분홍색 해당화\n",
      "남색의 파도우에 거부기모양의 섬\n",
      "섬우엔 병풍처럼 펼쳐진 푸른 솔숲\n",
      "그 솔숲에서 봄이면 날려오는\n",
      "노란 솔꽃가루 물결에 실리고\n",
      "여름내내 해당화 진한 향기\n",
      "바람타고 감도는 포구여서\n",
      "그 이름도 화진포\n",
      "그날이였다\n",
      "해방전 가진자들의 흥타령 울리던\n",
      "해변가 신작로따라\n",
      "차창에 석양빛 싣고\n",
      "달려오는 승용차 한대\n",
      "해넘이경치 보러오는걸가\n",
      "해당화 꽃구경 오는걸가\n",
      "하늘가엔 노을도 곱게 피는데\n",
      "어인 일인가\n",
      "기울어진 울바자 힘겹게 서있는\n",
      "마을어구에서 문득 멈춰서는 승용차\n",
      "슬픔을 먹고자란 생명인가\n",
      "시들은 유채꽃처럼\n",
      "얼굴이 노랗게 뜬 어린 소녀\n",
      "바다쪽에 눈길을 얹고\n",
      "마을길에 서있었다\n",
      "가난이 숨길수 없이 내비친듯\n",
      "다섯발가락이 다 나온\n",
      "터진 고무신을 신고 서있는 소녀\n",
      "그 모습에 눈길을 떼지 못하시며\n",
      "차에서 내리신 현숙한 녀사분과 자제분\n",
      "불쌍한 아이들을 두고서는\n",
      "눈물도 많으신분\n",
      "38°선 가까이서 그 모습을 보니\n",
      "가슴에 소금이 뿌려진듯\n",
      "더 아파 못 견디시는\n",
      "아, 그분은\n",
      "항일의 녀장군 김정숙어머님\n",
      "－몇살이예요?\n",
      "－여섯살!\n",
      "－왜 여기 서있나요?\n",
      "－아빠가 보고싶어서…\n",
      "－아빠는 어디 가셨게?\n",
      "－고기잡이 나갔다가\n",
      "  38°선이 막혀 못 온대요\n",
      "  돌아오면 꽃신을 꼭 사주겠다고 했는데…\n",
      "꿰진 신발과 해진 옷을 걸치고\n",
      "분렬조국의 기슭에 나와선\n",
      "어린 소녀\n",
      "품에 꼭 껴안으신 어머님\n",
      "어머님 눈빛은\n",
      "저도몰래 젖어드셨다\n",
      "어릴적 부암동 하촌마을에서\n",
      "피덩이 어린 조카를 안고\n",
      "오빠를 기다리던 그날이 생각나\n",
      "그날의 자신의 모습\n",
      "여기서 다시 보는것만 같아\n",
      "진정 그랬다\n",
      "일제놈들때문에 당한\n",
      "그 생리별의 아픔\n",
      "해가고 달가도 가실길 없는데\n",
      "미국놈들때문에 또다시\n",
      "이런 비극 당해야 한단 말인가\n",
      "어머님은 비분을 누르시며\n",
      "조용히 말씀하신다\n",
      "－얘야 우리 경치좋은 이곳에\n",
      "  이제 학교랑 유희장이랑 짓자꾸나\n",
      "  그때면\n",
      "  새 옷도 새 신발도 다 거저주려 한다\n",
      "  헤여진 아버지도 만나구 … 좋지?\n",
      "머리를 번쩍 든 소녀\n",
      "나서 처음 해빛을 마주한듯\n",
      "눈빛을 반짝이며 우러렀다\n",
      "다정하신 그분을\n",
      "가슴속에 무지개가 떴다\n",
      "그 고운 칠색에 고운 꿈을 실을제\n",
      "새 신을 안고 달려오신 자제분\n",
      "그분은 빨찌산의 아들 김정일장군님\n",
      "처녀애의 터진 고무신을 벗기고\n",
      "새 신발을 신겨주시였다\n",
      "－어서 신어라 이건 내 신발인데\n",
      "  네 발에 꼭 맞을거야\n",
      "  그리고 아빠때문에\n",
      "  너무 마음쓰지 말어\n",
      "  38°선 철조망을 걷어주시려\n",
      "  아버지 김일성장군님께서\n",
      "  우리 어머님과 함께 화진포에 오셨어\n",
      "화진포에 가면 신으라고\n",
      "수령님 사주신 신발\n",
      "어머님께서 신끈도 곱게 매여주시여\n",
      "아직 한번도 신지 않고\n",
      "아끼고아끼시던 새 구두\n",
      "아끼지 않고 주시였다\n",
      "겨레를 위해 늘 마음쓰시는\n",
      "수령님과 어머님사랑\n",
      "자신의 마음에 가득 담으시여\n",
      "아빠찾는 소녀의 가슴에\n",
      "기쁨으로 가득 안겨주시였다\n",
      "순간 솟구치는\n",
      "감사의 인사말 올리는것인가\n",
      "가랑가랑 눈굽에 구슬을 달고\n",
      "여섯살 어린 소녀\n",
      "아뢰인 다만 한마디\n",
      "오빠!－\n",
      "그렇다 그분이 누구신지\n",
      "소녀는 아직 알수 없었어도\n",
      "어린 가슴속에\n",
      "그분은 벌써 친오빠\n",
      "기쁨으로 우러른\n",
      "행복의 세상이시였다\n",
      "소녀는 달려간다\n",
      "새 신을 안고\n",
      "춤을 추듯 백사장으로\n",
      "아빠!－ 소리쳐 부르며\n",
      "그 소리\n",
      "바다가 멀리멀리 메아리치는데\n",
      "소녀가 찾는 아빠\n",
      "어디에 있는가\n",
      "어머님은 오래도록\n",
      "자리를 뜨지 못하신다\n",
      "산에서 얼고 굶으며\n",
      "피흘려 찾은 조국이건만\n",
      "마주하신것은\n",
      "갈라진 민족의 비극\n",
      "분렬의 아픈 상처\n",
      "산에서 10여성상 쌓이신 피로\n",
      "예와서 푸시면 얼마나 좋으랴\n",
      "해방된 조국의 명소에 오셨어도\n",
      "아름다운 경치 비켜서시여\n",
      "갈라진 겨레의 불행 안으시고\n",
      "자리를 뜨지 못하시나니\n",
      "오, 물어보자\n",
      "삼천리조국이여 화진포여\n",
      "너는 어머님께 아픔만 드리자고\n",
      "어제는 일제의 칼에 맞아 피흘리고\n",
      "오늘은 허리잘려 신음하느냐\n",
      "이렇게 오시였다 어머님은\n",
      "38°선이 보이는 분렬의 현장으로\n",
      "이 땅의 울분을 안으시고\n",
      "민족의 통한을 안으시고\n",
      "해방소원 안으셨던 가슴에\n",
      "통일소원 또다시 무겁게 안으시고\n",
      "차는 달린다 어둠을 뚫고\n",
      "아빠찾는 소녀의 모습\n",
      "갈라진 겨레의 아픔\n",
      "크나큰 위업속에 싣고\n",
      "오, 그날부터 화진포에\n",
      "어머님 휴식의 밤은 없었다\n",
      "날이 밝았다\n",
      "아빠가 돌아오면 보여주리\n",
      "새 신발 가슴에 안고\n",
      "이른 새벽부터\n",
      "바다가 모래불에 나와 선\n",
      "어린 소녀\n",
      "철썩 처절썩－\n",
      "몇백 몇천번이나 파도는\n",
      "기슭에 달려와 안겨도\n",
      "오늘도 안 오시는 아빠\n",
      "언제면 오실가\n",
      "저녁노을 등에 지고\n",
      "맥없이 집에 들어서는데\n",
      "그만 눈이 휘둥그래졌다\n",
      "엄마와 함께 부엌에서\n",
      "터진 부뚜막 손질하시는분\n",
      "그분이 어제저녁 마을길에서 만난\n",
      "그 고마우신 어머님이시였으니\n",
      "소녀의 얼굴엔 웃음꽃이 활짝 폈다\n",
      "세상에서 제일 좋은 큰어머님\n",
      "엄마와 함께 계시기에\n",
      "기쁨속에 새겨들었다\n",
      "큰어머님 엄마와 나누시는 말씀\n",
      "－세대주가 돌아와서\n",
      "  부뚜막수리를 하겠다고 했는데…\n",
      "  녀사님께 페를 끼쳐 정말 미안해요\n",
      "－괜찮아요 이제 세대주가 돌아오면\n",
      "  기다린 정 만난정 다 합쳐\n",
      "  밥을 맛있게 지어 대접하자요!\n",
      "친혈육인듯\n",
      "다정한 언니 동생인듯\n",
      "웃으며 허물없이 이야기를 나눌 때\n",
      "어린 소녀 어느새 달려와 안겼다\n",
      "－엄마 내가 어제 말하던\n",
      "  그 큰어머님이야\n",
      "－해선아! 나도 그렇게 생각했다\n",
      "모를수 없었다\n",
      "그분이 아니시면\n",
      "누가 화진포에\n",
      "이렇듯 큰 사랑 안고오시랴\n",
      "김정숙어머님! 그 이름은\n",
      "나라를 찾아주신\n",
      "김일성장군님 태양존함과 더불어\n",
      "삼천리에 빛나는 해발!\n",
      "아이들 손잡고 로인들 앞세우고\n",
      "동리사람들이 모여왔다\n",
      "친정집어머님을 모신듯\n",
      "사람들 빙－ 둘러앉은 해선이네 집\n",
      "새 삶의 기쁨을 터치는\n",
      "글방인가 노래방인가 웃음방인가\n",
      "함께 오신 자제분 또박또박 써주신\n",
      "《삼천리 우리 나라》 글읽는 소리\n",
      "어머님 배워주신\n",
      "《김일성장군의 노래》 부르는 소리\n",
      "수령님 모신 통일조국에서 행복하게 살\n",
      "그날을 그려보는 웃음소리\n",
      "아, 분렬의 종처인양 옹기종기\n",
      "설음이 돋아있는 동네\n",
      "집집마다 가슴마다 기쁨을 채워주는\n",
      "백두에서 떠나온 사랑의 큰 세계여\n",
      "그 품에 안겨\n",
      "사랑이 무엇인지 하나씩 깨달아가는\n",
      "화진포사람들의\n",
      "글소리 노래소리 웃음소리여\n",
      "밤이 깊었다\n",
      "따로 마련한 숙소\n",
      "마다하시는 어머님께\n",
      "한 녀인이 말씀올린다\n",
      "－녀사님, 그럼 이 모기장만이라도…\n",
      "풀엉킨 산기슭의 작은 집\n",
      "여름밤 모기장이야 어이 마다하시랴\n",
      "하지만 어머님\n",
      "누에실로 엮은 수수한 모기장앞에\n",
      "생각깊이 이으시는 말씀\n",
      "－해선이 아버지랑 함께 간 사람들이\n",
      "  지금 혈육들 생각하며\n",
      "  밤거리를 헤매는지 어떻게 알겠어요\n",
      "  그런데 제가 어떻게 호강스럽게\n",
      "  비단모기장을 치고 눕겠어요?!\n",
      "이 무슨 말씀이신가\n",
      "산에서 눈깔고 가랑잎덮고 쉬시며\n",
      "겪으신 고생 얼마이신데\n",
      "그러면 우린 어떻게 하느냐며\n",
      "해선이 어머닌 울어버린다\n",
      "－해선이 어머니, 이러지 마세요\n",
      "  나에겐 모포 한장이면 돼요\n",
      "  지금 수령님께서는 조국의 통일을 위해\n",
      "  화진포사람들의 생활을 위해\n",
      "  이 밤도 지새고계셔요\n",
      "  조국이 통일되는 그날까지\n",
      "  나는 백두산에서 몸에 밴\n",
      "  유격대생활습성을 바꿀것 같지 못해요\n",
      "－녀사님!\n",
      "－김정숙어머님!\n",
      "아, 이 밤을 울었다\n",
      "숲속의 이름 모를 풀잎마저\n",
      "맑은 이슬 소리내여 떨구며\n",
      "못 이룬 통일앞에 서신 어머님껜\n",
      "수수한 견사모기장마저\n",
      "그리도 사치한것이란 말인가\n",
      "이밤엔 어유등도\n",
      "안타까움에 타고탔다\n",
      "누구나 누리는 그 작은 권리\n",
      "어머님은 향유하시면 안되신단 말인가\n",
      "어느덧 밤은 깊어\n",
      "외로운 포구에 정적도 깊어\n",
      "화진포사람들 깊은 잠 들었건만\n",
      "마당가에 나오신\n",
      "김정숙어머님\n",
      "마음을 진정하지 못하신다\n",
      "만주벌 눈바람속에서\n",
      "풍찬로숙하며\n",
      "탄알이 비발치는 전장을\n",
      "총들고 달리시며\n",
      "시련을 넘어 죽음을 넘어\n",
      "기어이 찾은 조국이건만\n",
      "그 조국의 허리에\n",
      "가시철조망이 칭칭 감기고\n",
      "해방만세의 감격 터져올랐던\n",
      "이 8월의 여름하늘아래서\n",
      "얼어드는 가슴안고 사람들 살고있으니\n",
      "견딜수 없으시였다\n",
      "용납할수 없으시였다\n",
      "한몸을 깡그리 불태워서라도\n",
      "원한의 그 찬덩어리 모두 녹이리라\n",
      "어머님 가슴속에선 선언이 울리셨다\n",
      "오, 진정\n",
      "이 땅의 한사람한사람이\n",
      "자신의 체온다해 품어주시는\n",
      "친혈육 친자식이여서\n",
      "이 땅의 한치한치가\n",
      "자신의 몸 한부분 같으시여\n",
      "조국앞에 서신 어머님은 그대로\n",
      "금강석도 녹여버릴\n",
      "불덩이 지니신 사랑의 화신이시였다\n",
      "삼천리를 품으신 하늘이시였다\n",
      "진정 억만금이 있다 해도\n",
      "그를 위해 모두 바치셨을\n",
      "통일, 통일은 어머님의\n",
      "최고의 기쁨\n",
      "최상의 재부\n",
      "최대의 소원\n",
      "사모님이라 부르는것조차\n",
      "한번 허락지 않으시고\n",
      "김일성장군님 통일전사로\n",
      "낮과 밤을 이으시는 어머님이시여\n",
      "한몸을 깡그리 불태우시는 녀장군이시여\n"
     ]
    }
   ],
   "source": [
    "scores_poem = []\n",
    "for line in poem:\n",
    "    if len(line) > 3:\n",
    "        print(line)\n",
    "        #print(komoran.pos(line))\n",
    "        try:\n",
    "            score = compute_sentence_score(line.strip())\n",
    "        except:\n",
    "            pass\n",
    "        scores_poem.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00016278879475836874"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(scores_poem)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
